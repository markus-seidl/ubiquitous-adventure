{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bucket = 'sagemaker-object-detection-test-200408' # custom bucket name.\n",
    "# bucket = sess.default_bucket()\n",
    "prefix = 'ObjectDetection-v0'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "DATA = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare / Download datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download / Unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "\n",
    "# MSCOCO validation image files\n",
    "download('http://images.cocodataset.org/zips/val2017.zip')\n",
    "download('http://images.cocodataset.org/annotations/annotations_trainval2017.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p data/coco || true\n",
    "mv val2017.zip data/coco\n",
    "mv annotations_trainval2017.zip data/coco\n",
    "cd data/coco\n",
    "unzip -qo val2017.zip || true\n",
    "unzip -qo annotations_trainval2017.zip || true\n",
    "rm val2017.zip annotations_trainval2017.zip || true\n",
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#Create folders to store the data and annotation files\n",
    "#cd data/coco\n",
    "#rm -rf generated train train_annotation validation validation_annotation || true\n",
    "#mkdir generated train train_annotation validation validation_annotation || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO_CAT_IDS [17]\n",
      "COCO_DOG_IDS [18]\n"
     ]
    }
   ],
   "source": [
    "COCO_CAT_IDS = []\n",
    "COCO_DOG_IDS = []\n",
    "\n",
    "file_name = './data/coco/annotations/instances_val2017.json'\n",
    "with open(file_name) as f:\n",
    "    js = json.load(f)\n",
    "    images = js['images']\n",
    "    categories = js['categories']\n",
    "    for c in categories:\n",
    "        n = c['name']\n",
    "        i = c['id']\n",
    "        if n == 'cat':\n",
    "            COCO_CAT_IDS.append(i)\n",
    "        if n == 'dog':\n",
    "            COCO_DOG_IDS.append(i)\n",
    "            \n",
    "print(\"COCO_CAT_IDS %s\" % COCO_CAT_IDS)\n",
    "print(\"COCO_DOG_IDS %s\" % COCO_DOG_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cat_or_dog(category):\n",
    "    if category in COCO_CAT_IDS or category in COCO_CAT_IDS:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "#def get_coco_mapper():\n",
    "#    original_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "#                    21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
    "#                    41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
    "#                    61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
    "#                    81, 82, 84, 85, 86, 87, 88, 89, 90]\n",
    "#    iter_counter = 0\n",
    "#    COCO = {}\n",
    "#    for orig in original_list:\n",
    "#        if is_cat_or_dog(orig):\n",
    "#            COCO[orig] = iter_counter\n",
    "#            iter_counter += 1\n",
    "#    return COCO\n",
    "\n",
    "#def get_mapper_fn(map):  \n",
    "#    def mapper(in_category):\n",
    "#        return map[in_category]\n",
    "#    return mapper\n",
    "\n",
    "#fix_index_mapping = get_mapper_fn(get_coco_mapper())\n",
    "\n",
    "def fix_index_mapping(map):\n",
    "    if map in COCO_DOG_IDS:\n",
    "        return 0\n",
    "    if map in COCO_CAT_IDS:\n",
    "        return 1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Images from COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_annotations_from(file_name, root_dir):\n",
    "    ret = list()\n",
    "    with open(file_name) as f:\n",
    "        js = json.load(f)\n",
    "        images = js['images']\n",
    "        categories = js['categories']\n",
    "        annotations = js['annotations']\n",
    "        \n",
    "        annotation_dict = dict()\n",
    "        for a in annotations:\n",
    "            image_id = a['image_id']\n",
    "            if image_id not in annotation_dict:\n",
    "                annotation_dict[image_id] = list()\n",
    "                \n",
    "            annotation_dict[image_id].append(a)\n",
    "                \n",
    "        for i in images:\n",
    "            jsonFile = i['file_name']\n",
    "            jsonFile = jsonFile.split('.')[0]+'.json'\n",
    "\n",
    "            line = {}\n",
    "            line['file'] = root_dir + '/' + i['file_name'] # <<<< needed\n",
    "            line['image_size'] = [int(i['height']), int(i['width']), 3] # <<<< needed\n",
    "            line['annotations'] = []\n",
    "            line['ids'] = []\n",
    "            line['boxes'] = []\n",
    "            if i['id'] not in annotation_dict:\n",
    "                # There are pictures with no annotations(!)\n",
    "                continue\n",
    "            for j in annotation_dict[i['id']]:\n",
    "                if j['image_id'] == i['id'] and len(j['bbox']) > 0:\n",
    "                    if not is_cat_or_dog(j['category_id']):\n",
    "                        continue\n",
    "\n",
    "                    line['annotations'].append({\n",
    "                        'class_id': fix_index_mapping(j['category_id']),\n",
    "                        'top':int(j['bbox'][1]),\n",
    "                        'left':int(j['bbox'][0]),\n",
    "                        'width':int(j['bbox'][2]),\n",
    "                        'height':int(j['bbox'][3])\n",
    "                    })\n",
    "                    line['boxes'].append([j['bbox'][0], j['bbox'][1], j['bbox'][2], j['bbox'][3]]) # <<<< needed\n",
    "                    line['ids'].append(fix_index_mapping(j['category_id'])) # <<<< needed\n",
    "            if line['annotations']:\n",
    "                ret.append(line)\n",
    "    return ret\n",
    "\n",
    "coco_val_annot = load_annotations_from('./data/coco/annotations/instances_val2017.json', './data/coco/val2017')\n",
    "for a in coco_val_annot:\n",
    "    DATA.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data 165 , val data 19\n"
     ]
    }
   ],
   "source": [
    "length = len(DATA)\n",
    "amount_train = 0.9\n",
    "\n",
    "split_idx = int(length*amount_train)\n",
    "\n",
    "TRAIN_DATA = DATA[:split_idx]\n",
    "VAL_DATA = DATA[split_idx:]\n",
    "\n",
    "print(\"Train data\", len(TRAIN_DATA), \", val data\", len(VAL_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line(img_path, im_shape, boxes, ids, idx):\n",
    "    \"\"\" FROM https://gluon-cv.mxnet.io/build/examples_datasets/detection_custom.html \"\"\"\n",
    "    h, w, c = im_shape\n",
    "    # for header, we use minimal length 2, plus width and height\n",
    "    # with A: 4, B: 5, C: width, D: height\n",
    "    A = 4\n",
    "    B = 5\n",
    "    C = w\n",
    "    D = h\n",
    "    # concat id and bboxes\n",
    "    labels = np.hstack((ids.reshape(-1, 1), boxes)).astype('float')\n",
    "    # normalized bboxes (recommanded)\n",
    "    labels[:, (1, 3)] /= float(w)\n",
    "    labels[:, (2, 4)] /= float(h)\n",
    "    # flatten\n",
    "    labels = labels.flatten().tolist()\n",
    "    str_idx = [str(idx)]\n",
    "    str_header = [str(x) for x in [A, B, C, D]]\n",
    "    str_labels = [str(x) for x in labels]\n",
    "    str_path = [img_path]\n",
    "    line = '\\t'.join(str_idx + str_header + str_labels + str_path) + '\\n'\n",
    "    return line\n",
    "\n",
    "def write_lst(annot, out, idx_start=0):\n",
    "    idx = idx_start\n",
    "    with open(out, 'w+') as f:\n",
    "        for a in annot:\n",
    "            line = create_line(a['file'], np.array(a['image_size']), np.array(a['boxes']), np.array(a['ids']), idx)\n",
    "            f.write(line)\n",
    "            idx += 1\n",
    "    return idx\n",
    "\n",
    "write_lst(TRAIN_DATA, \"train.lst\", 0)\n",
    "write_lst(VAL_DATA, \"val.lst\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate rec file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating .rec file from /home/ec2-user/SageMaker/ubiquitous-adventure/v1/train.lst in /home/ec2-user/SageMaker/ubiquitous-adventure/v1\n",
      "time: 0.07296228408813477  count: 0\n",
      "Creating .rec file from /home/ec2-user/SageMaker/ubiquitous-adventure/v1/val.lst in /home/ec2-user/SageMaker/ubiquitous-adventure/v1\n",
      "time: 0.06447672843933105  count: 0\n",
      "CPU times: user 1.97 ms, sys: 9.2 ms, total: 11.2 ms\n",
      "Wall time: 5.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "./im2rec.py 'train.lst' '.' --resize 512 --pack-label --num-thread 2\n",
    "./im2rec.py 'val.lst' '.' --resize 512 --pack-label --num-thread 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Read first image of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "train_annotation_channel = prefix + '/train_annotation'\n",
    "validation_annotation_channel = prefix + '/validation_annotation'\n",
    "\n",
    "sess.upload_data(path='train', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='validation', bucket=bucket, key_prefix=validation_channel)\n",
    "sess.upload_data(path='train_annotation', bucket=bucket, key_prefix=train_annotation_channel)\n",
    "sess.upload_data(path='validation_annotation', bucket=bucket, key_prefix=validation_annotation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_annotation = 's3://{}/{}'.format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = 's3://{}/{}'.format(bucket, validation_annotation_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-object-detection-test-200408/ObjectDetection-v0/output'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "s3_output_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
