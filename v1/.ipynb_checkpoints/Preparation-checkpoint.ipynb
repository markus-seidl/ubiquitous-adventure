{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the COCO Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download / Unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-object-detection-test-200408' # custom bucket name.\n",
    "# bucket = sess.default_bucket()\n",
    "prefix = 'ObjectDetection-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::065122976270:role/service-role/AmazonSageMaker-ExecutionRole-20200403T093426\n",
      "CPU times: user 773 ms, sys: 61.5 ms, total: 835 ms\n",
      "Wall time: 896 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "\n",
    "# MSCOCO validation image files\n",
    "download('http://images.cocodataset.org/zips/val2017.zip')\n",
    "download('http://images.cocodataset.org/annotations/annotations_trainval2017.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "unzip -qo val2017.zip || true\n",
    "unzip -qo annotations_trainval2017.zip || true\n",
    "rm val2017.zip annotations_trainval2017.zip || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Create folders to store the data and annotation files\n",
    "rm -rf generated train train_annotation validation validation_annotation || true\n",
    "mkdir generated train train_annotation validation validation_annotation || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT_IDS [17]\n",
      "DOG_IDS [18]\n"
     ]
    }
   ],
   "source": [
    "CAT_IDS = []\n",
    "DOG_IDS = []\n",
    "\n",
    "file_name = './annotations/instances_val2017.json'\n",
    "with open(file_name) as f:\n",
    "    js = json.load(f)\n",
    "    images = js['images']\n",
    "    categories = js['categories']\n",
    "    for c in categories:\n",
    "        n = c['name']\n",
    "        i = c['id']\n",
    "        if n == 'cat':\n",
    "            CAT_IDS.append(i)\n",
    "        if n == 'dog':\n",
    "            DOG_IDS.append(i)\n",
    "            \n",
    "print(\"CAT_IDS %s\" % CAT_IDS)\n",
    "print(\"DOG_IDS %s\" % DOG_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cat_or_dog(category):\n",
    "    if category in CAT_IDS or category in DOG_IDS:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_coco_mapper():\n",
    "    original_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "                    21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
    "                    41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
    "                    61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
    "                    81, 82, 84, 85, 86, 87, 88, 89, 90]\n",
    "    iter_counter = 0\n",
    "    COCO = {}\n",
    "    for orig in original_list:\n",
    "        if is_cat_or_dog(orig):\n",
    "            COCO[orig] = iter_counter\n",
    "            iter_counter += 1\n",
    "    return COCO\n",
    "\n",
    "def get_mapper_fn(map):  \n",
    "    def mapper(in_category):\n",
    "        return map[in_category]\n",
    "    return mapper\n",
    "\n",
    "fix_index_mapping = get_mapper_fn(get_coco_mapper())\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map annotations to sagemaker format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './annotations/instances_val2017.json'\n",
    "with open(file_name) as f:\n",
    "    js = json.load(f)\n",
    "    images = js['images']\n",
    "    categories = js['categories']\n",
    "    annotations = js['annotations']\n",
    "    for i in images:\n",
    "        jsonFile = i['file_name']\n",
    "        jsonFile = jsonFile.split('.')[0]+'.json'\n",
    "        \n",
    "        line = {}\n",
    "        line['file'] = i['file_name']\n",
    "        line['image_size'] = [{\n",
    "            'width':int(i['width']),\n",
    "            'height':int(i['height']),\n",
    "            'depth':3\n",
    "        }]\n",
    "        line['annotations'] = []\n",
    "        line['categories'] = []\n",
    "        for j in annotations:\n",
    "            if j['image_id'] == i['id'] and len(j['bbox']) > 0:\n",
    "                if not is_cat_or_dog(j['category_id']):\n",
    "                    continue\n",
    "                \n",
    "                line['annotations'].append({\n",
    "                    'class_id':int(fix_index_mapping(j['category_id'])),\n",
    "                    'top':int(j['bbox'][1]),\n",
    "                    'left':int(j['bbox'][0]),\n",
    "                    'width':int(j['bbox'][2]),\n",
    "                    'height':int(j['bbox'][3])\n",
    "                })\n",
    "                class_name = ''\n",
    "                for k in categories:\n",
    "                    if int(j['category_id']) == k['id']:\n",
    "                        class_name = str(k['name'])\n",
    "                assert class_name is not ''\n",
    "                line['categories'].append({\n",
    "                    'class_id':int(j['category_id']),\n",
    "                    'name':class_name\n",
    "                })\n",
    "        if line['annotations']:\n",
    "            with open(os.path.join('generated', jsonFile),'w') as p:\n",
    "                json.dump(line,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 349 images have annotation files\n"
     ]
    }
   ],
   "source": [
    "jsons = os.listdir('generated')\n",
    "print ('There are {} images have annotation files'.format(len(jsons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data and upload to S3 for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split idx 174\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "jsons = os.listdir('generated')\n",
    "split_idx = int(len(jsons)/2)\n",
    "print(\"Split idx %i\" % split_idx)\n",
    "\n",
    "train_jsons = jsons[:split_idx]\n",
    "val_jsons = jsons[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving training files to the training folders\n",
    "for i in train_jsons:\n",
    "    image_file = './val2017/'+i.split('.')[0]+'.jpg'\n",
    "    if not os.path.exists(image_file):\n",
    "        print(\"Train image file not available %s\" % image_file)\n",
    "        continue\n",
    "    \n",
    "    shutil.move(image_file, './train/')\n",
    "    shutil.move('./generated/'+i, './train_annotation/')\n",
    "\n",
    "#Moving validation files to the validation folders\n",
    "for i in val_jsons:\n",
    "    image_file = './val2017/'+i.split('.')[0]+'.jpg'\n",
    "    if not os.path.exists(image_file):\n",
    "        print(\"Validation image file not available %s\" % image_file)\n",
    "        continue\n",
    "    shutil.move(image_file, './validation/')\n",
    "    shutil.move('./generated/'+i, './validation_annotation/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "train_annotation_channel = prefix + '/train_annotation'\n",
    "validation_annotation_channel = prefix + '/validation_annotation'\n",
    "\n",
    "sess.upload_data(path='train', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='validation', bucket=bucket, key_prefix=validation_channel)\n",
    "sess.upload_data(path='train_annotation', bucket=bucket, key_prefix=train_annotation_channel)\n",
    "sess.upload_data(path='validation_annotation', bucket=bucket, key_prefix=validation_annotation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_annotation = 's3://{}/{}'.format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = 's3://{}/{}'.format(bucket, validation_annotation_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-object-detection-test-200408/ObjectDetection-v0/output'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "s3_output_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
