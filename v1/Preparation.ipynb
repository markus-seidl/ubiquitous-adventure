{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bucket = 'sagemaker-object-detection-test-200408' # custom bucket name.\n",
    "# bucket = sess.default_bucket()\n",
    "prefix = 'ObjectDetection-v0'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "DATA = []\n",
    "TYPE = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install --upgrade mxnet gluoncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare / Download datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download / Unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "\n",
    "# MSCOCO validation image files\n",
    "download('http://images.cocodataset.org/zips/train2017.zip')\n",
    "download('http://images.cocodataset.org/annotations/annotations_trainval2017.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p data/coco || true\n",
    "mv train2017.zip data/coco\n",
    "mv annotations_trainval2017.zip data/coco\n",
    "cd data/coco\n",
    "unzip -qo train2017.zip || true\n",
    "unzip -qo annotations_trainval2017.zip || true\n",
    "# rm val2017.zip annotations_trainval2017.zip || true\n",
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#Create folders to store the data and annotation files\n",
    "#cd data/coco\n",
    "#rm -rf generated train train_annotation validation validation_annotation || true\n",
    "#mkdir generated train train_annotation validation validation_annotation || true"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare Mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO_CAT_IDS [17]\n",
      "COCO_DOG_IDS [18]\n",
      "COCO_HUMAN_IDS [1]\n"
     ]
    }
   ],
   "source": [
    "COCO_CAT_IDS = []\n",
    "COCO_DOG_IDS = []\n",
    "COCO_HUMAN_IDS = []\n",
    "\n",
    "file_name = './data/coco/annotations/instances_' + TYPE + '2017.json'\n",
    "\n",
    "with open(file_name) as f:\n",
    "    js = json.load(f)\n",
    "    images = js['images']\n",
    "    categories = js['categories']\n",
    "    for c in categories:\n",
    "        n = c['name']\n",
    "        i = c['id']\n",
    "        if n == 'cat':\n",
    "            COCO_CAT_IDS.append(i)\n",
    "        if n == 'dog':\n",
    "            COCO_DOG_IDS.append(i)\n",
    "        if n == 'person':\n",
    "            COCO_HUMAN_IDS.append(i)\n",
    "            \n",
    "print(\"COCO_CAT_IDS %s\" % COCO_CAT_IDS)\n",
    "print(\"COCO_DOG_IDS %s\" % COCO_DOG_IDS)\n",
    "print(\"COCO_HUMAN_IDS %s\" % COCO_HUMAN_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def is_relevant(category):\n",
    "    if category in COCO_CAT_IDS or category in COCO_DOG_IDS or category in COCO_HUMAN_IDS:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def fix_index_mapping(map):\n",
    "    if map in COCO_CAT_IDS:\n",
    "        return 1\n",
    "    if map in COCO_DOG_IDS:\n",
    "        return 2\n",
    "    if map in COCO_HUMAN_IDS:\n",
    "        return 3\n",
    "    return 0"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Register Images from COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def load_annotations_from(file_name, root_dir):\n",
    "    ret = list()\n",
    "    with open(file_name) as f:\n",
    "        js = json.load(f)\n",
    "        images = js['images']\n",
    "        categories = js['categories']\n",
    "        annotations = js['annotations']\n",
    "        \n",
    "        annotation_dict = dict()\n",
    "        for a in annotations:\n",
    "            image_id = a['image_id']\n",
    "            if image_id not in annotation_dict:\n",
    "                annotation_dict[image_id] = list()\n",
    "                \n",
    "            annotation_dict[image_id].append(a)\n",
    "                \n",
    "        for i in images:\n",
    "            jsonFile = i['file_name']\n",
    "            jsonFile = jsonFile.split('.')[0]+'.json'\n",
    "\n",
    "            line = {}\n",
    "            line['file'] = root_dir + '/' + i['file_name'] # <<<< needed\n",
    "            line['image_size'] = [int(i['height']), int(i['width']), 3] # <<<< needed\n",
    "            line['annotations'] = []\n",
    "            line['ids'] = []\n",
    "            line['boxes'] = []\n",
    "            if i['id'] not in annotation_dict:\n",
    "                # There are pictures with no annotations(!)\n",
    "                continue\n",
    "            for j in annotation_dict[i['id']]:\n",
    "                if j['image_id'] == i['id'] and len(j['bbox']) > 0:\n",
    "                    if not is_relevant(j['category_id']):\n",
    "                        continue\n",
    "\n",
    "                    line['annotations'].append({\n",
    "                        'class_id': fix_index_mapping(j['category_id']),\n",
    "                        'top':int(j['bbox'][1]),\n",
    "                        'left':int(j['bbox'][0]),\n",
    "                        'width':int(j['bbox'][2]),\n",
    "                        'height':int(j['bbox'][3])\n",
    "                    })\n",
    "                    line['boxes'].append([j['bbox'][0], j['bbox'][1], j['bbox'][2], j['bbox'][3]]) # <<<< needed\n",
    "                    line['ids'].append(fix_index_mapping(j['category_id'])) # <<<< needed\n",
    "            if line['annotations']:\n",
    "                ret.append(line)\n",
    "    return ret\n",
    "\n",
    "coco_test_annot = load_annotations_from('./data/coco/annotations/instances_' + TYPE + '2017.json', './data/coco/' + TYPE + '2017')\n",
    "for a in coco_test_annot:\n",
    "    DATA.append(a)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Split Data into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data 0 , val data 2945\n"
     ]
    }
   ],
   "source": [
    "length = len(DATA)\n",
    "amount_train = 1.0\n",
    "\n",
    "split_idx = int(length*amount_train)\n",
    "\n",
    "TRAIN_DATA = [] #DATA[:split_idx]\n",
    "VAL_DATA = DATA #DATA[split_idx:]\n",
    "\n",
    "print(\"Train data\", len(TRAIN_DATA), \", val data\", len(VAL_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def create_line(img_path, im_shape, boxes, ids, idx):\n",
    "    \"\"\" FROM https://gluon-cv.mxnet.io/build/examples_datasets/detection_custom.html \"\"\"\n",
    "    h, w, c = im_shape\n",
    "    # for header, we use minimal length 2, plus width and height\n",
    "    # with A: 4, B: 5, C: width, D: height\n",
    "    A = 4\n",
    "    B = 5\n",
    "    C = w\n",
    "    D = h\n",
    "    # concat id and bboxes\n",
    "    labels = np.hstack((ids.reshape(-1, 1), boxes)).astype('float')\n",
    "    # normalized bboxes (recommanded)\n",
    "    labels[:, (1, 3)] /= float(w)\n",
    "    labels[:, (2, 4)] /= float(h)\n",
    "    # flatten\n",
    "    labels = labels.flatten().tolist()\n",
    "    str_idx = [str(idx)]\n",
    "    str_header = [str(x) for x in [A, B, C, D]]\n",
    "    str_labels = [str(x) for x in labels]\n",
    "    str_path = [img_path]\n",
    "    line = '\\t'.join(str_idx + str_header + str_labels + str_path) + '\\n'\n",
    "    return line\n",
    "\n",
    "def write_lst(annot, out, idx_start=0):\n",
    "    idx = idx_start\n",
    "    with open(out, 'w+') as f:\n",
    "        for a in annot:\n",
    "            line = create_line(a['file'], np.array(a['image_size']), np.array(a['boxes']), np.array(a['ids']), idx)\n",
    "            f.write(line)\n",
    "            idx += 1\n",
    "    return idx\n",
    "\n",
    "#write_lst(TRAIN_DATA, \"train.lst\", 0)\n",
    "write_lst(VAL_DATA, \"val.lst\", 0)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "2945"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%bash\n",
    "./im2rec.py 'train.lst' '.' --resize 224 --pack-label --num-thread 4\n",
    "./im2rec.py 'val.lst' '.' --resize 224 --pack-label --num-thread 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Read first image of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "record = mx.recordio.MXIndexedRecordIO('val.idx', 'val.rec', 'r')\n",
    "for i in range(1):\n",
    "    item = record.read()\n",
    "    header, s = mx.recordio.unpack_img(item)\n",
    "\n",
    "imshow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = mx.recordio.MXIndexedRecordIO('train.idx', 'train.rec', 'r')\n",
    "for i in range(1):\n",
    "    item = record.read()\n",
    "    header, s = mx.recordio.unpack_img(item)\n",
    "\n",
    "imshow(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3 - TODO (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "train_annotation_channel = prefix + '/train_annotation'\n",
    "validation_annotation_channel = prefix + '/validation_annotation'\n",
    "\n",
    "sess.upload_data(path='train', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='validation', bucket=bucket, key_prefix=validation_channel)\n",
    "sess.upload_data(path='train_annotation', bucket=bucket, key_prefix=train_annotation_channel)\n",
    "sess.upload_data(path='validation_annotation', bucket=bucket, key_prefix=validation_annotation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_annotation = 's3://{}/{}'.format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = 's3://{}/{}'.format(bucket, validation_annotation_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "s3_output_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}